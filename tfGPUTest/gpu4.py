# -*- coding: utf-8 -*-
"""CNN_TF_Code1_Assignment1_Solution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18UJaBOphzR849jBosz9T4NdeO4UGnpwR
"""

import tensorflow as tf
from datetime import datetime
import time
old_v = tf.logging.get_verbosity()
tf.logging.set_verbosity(tf.logging.ERROR)

# Import MNIST data
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)

# Parameters
learning_rate = 0.001 #learning rate or step size for optimization
batch_size = 100 # batch size to input the in batches
display_step = 1
model_path = "EventsLogs\\model.ckpt" # if you don't have this folder please create one

# Network Parameters
n_input = 784 # MNIST data input (img shape: 28*28)
n_classes = 10 # MNIST total classes (0-9 digits)

# Create some wrappers for simplicity
def conv2d(x, W, b, strides=1):
    # Conv2D wrapper, with bias and relu activation
    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')
    x = tf.nn.bias_add(x, b)
    return tf.nn.relu(x)


def maxpool2d(x, k=2):
    # MaxPool2D wrapper
    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],
                          padding='SAME')


# Store layers weights & biases
weights = {
    # 5x5 conv, 1 input, 32 outputs
    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),
    # 5x5 conv, 32 inputs, 64 outputs
    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),
    # fully connected, 7*7*64 inputs, 1024 outputs
    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),
    # 1024 inputs, 10 outputs (class prediction)
    'out': tf.Variable(tf.random_normal([1024, n_classes]))
}

biases = {
    'bc1': tf.Variable(tf.random_normal([32])),
    'bc2': tf.Variable(tf.random_normal([64])),
    'bd1': tf.Variable(tf.random_normal([1024])),
    'out': tf.Variable(tf.random_normal([n_classes]))
}

# Create model
def conv_net(x, weights, biases, dropout):
    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)
    # Reshape to match picture format [Height x Width x Channel]
    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]
    x = tf.reshape(x, shape=[-1, 28, 28, 1])#-1 is used to infer the shape (here number of batches)

    # Convolution Layer
    conv1 = conv2d(x, weights['wc1'], biases['bc1'])
    # Max Pooling (down-sampling)
    conv1 = maxpool2d(conv1, k=2)

    # Convolution Layer
    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])
    # Max Pooling (down-sampling)
    conv2 = maxpool2d(conv2, k=2)

    # Fully connected layer
    # Reshape conv2 output to fit fully connected layer input
    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])
    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])
    fc1 = tf.nn.relu(fc1)
    # Apply Dropout
    fc1 = tf.nn.dropout(fc1, dropout)
    # Output, class prediction
    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])
    return out

with tf.device('/cpu:0'):

  # Choose the optimizer
  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
  with tf.device('/gpu:0'):
    # tf Graph input: Placeholders
    x = tf.placeholder("float", [None, n_input])
    y = tf.placeholder("float", [None, n_classes])
    keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)
    # Construct model
    pred = conv_net(x, weights, biases, keep_prob)
    # Define loss function
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))
    # Train operation
    Train_op =  optimizer.minimize(loss)

  # Prediction for the Test model
  correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
  # Calculate accuracy
  accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))

  # Initialize the variables (i.e. assign their default value)
  init = tf.global_variables_initializer()

  # 'Saver' op to save and restore all the variables
  # saver = tf.train.Saver()
  config = tf.ConfigProto() # a protocol message to set configurations
  config.gpu_options.allow_growth = True #only grow the memory usage as it is needed by the process
  config.allow_soft_placement = True # For TensorFlow to automatically choose an existing and supported device to run the operations in case the specified one doesn't exist
  config.log_device_placement = True #To find out which devices your operations and tensors are assigned to, create the session with log_device_placement configuration option set to True

# Running first session
  print("Starting 1st session...")
  with tf.Session(config=config) as sess:

      # Run the initializer
      sess.run(init)

      # Training cycle
      for epoch in range(1):
          avg_loss = 0.
          total_batch = int(mnist.train.num_examples/batch_size) #250#instaed of: int(mnist.train.num_examples/batch_size) #55000/100=550
          # Loop over all batches
          ts=time.time()
          for i in range(total_batch):
              batch_x, batch_y = mnist.train.next_batch(batch_size)
              # Run optimization op (backprop) and cost op (to get loss value)
              # feed_dict is a speciall dictionary for feeding the input data
              # A feed_dict takes the form of:
              # feed_dict = {<placeholder>: <tensor of values to be passed for placeholder>,....  }
              _, c = sess.run([Train_op, loss], feed_dict={x: batch_x,
                                                            y: batch_y, keep_prob: 0.8})
              # Compute average loss
              avg_loss += c / total_batch
          # Display logs per epoch step
          te=time.time()-ts
          if epoch % display_step == 0:
              print("Epoch:", '%04d' % (epoch+1), "loss=", \
                  "{:.9f}".format(avg_loss), "and it takes: {:.5f} seconds" .format(te))
      print("First Optimization Finished!")

      # Test model
      # Calculate accuracy
      #print("Accuracy:", accuracy.eval({x: mnist.test.images, y: mnist.test.labels, keep_prob: 1}))
      
      #################### calculate test accuracy per batch if memory is not enough on gpu or cpu#########
      #Sum_AccPerBatch = 0.
      #total_batch = int(mnist.test.num_examples/batch_size) #250#instaed of: int(mnist.train.num_examples/batch_size) #55000/100=550
      ## Loop over all batches
      #for i in range(total_batch):
        #batch_x, batch_y = mnist.test.next_batch(batch_size)
        #Acc = sess.run(accuracy, feed_dict={x: batch_x,y: batch_y, keep_prob: 1})
        ## Sum All Accuracies
        #Sum_AccPerBatch += Acc
      #Accuracy_avg = Sum_AccPerBatch/total_batch

      #print("Accuracy_avg:{:.9f}".format(Accuracy_avg))
